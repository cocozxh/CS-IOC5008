{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20651,
     "status": "ok",
     "timestamp": 1592099680147,
     "user": {
      "displayName": "子豪盛",
      "photoUrl": "",
      "userId": "05777601522634171836"
     },
     "user_tz": -480
    },
    "id": "yVh4aZJBXUdo",
    "outputId": "4b708e84-cb45-4a30-8c1b-4677f18c9c8a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmTAH95jXsnP"
   },
   "source": [
    "### nets.CSPdarknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37HotMBvXuIb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "#-------------------------------------------------#\n",
    "#   MISH激活函数\n",
    "#-------------------------------------------------#\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "#-------------------------------------------------#\n",
    "#   卷积块\n",
    "#   CONV+BATCHNORM+MISH\n",
    "#-------------------------------------------------#\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(BasicConv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   CSPdarknet的结构块的组成部分\n",
    "#   内部堆叠的残差块\n",
    "#---------------------------------------------------#\n",
    "class Resblock(nn.Module):\n",
    "    def __init__(self, channels, hidden_channels=None, residual_activation=nn.Identity()):\n",
    "        super(Resblock, self).__init__()\n",
    "\n",
    "        if hidden_channels is None:\n",
    "            hidden_channels = channels\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            BasicConv(channels, hidden_channels, 1),\n",
    "            BasicConv(hidden_channels, channels, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   CSPdarknet的结构块\n",
    "#   存在一个大残差边\n",
    "#   这个大残差边绕过了很多的残差结构\n",
    "#---------------------------------------------------#\n",
    "class Resblock_body(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, first):\n",
    "        super(Resblock_body, self).__init__()\n",
    "\n",
    "        self.downsample_conv = BasicConv(in_channels, out_channels, 3, stride=2)\n",
    "\n",
    "        if first:\n",
    "            self.split_conv0 = BasicConv(out_channels, out_channels, 1)\n",
    "            self.split_conv1 = BasicConv(out_channels, out_channels, 1)  \n",
    "            self.blocks_conv = nn.Sequential(\n",
    "                Resblock(channels=out_channels, hidden_channels=out_channels//2),\n",
    "                BasicConv(out_channels, out_channels, 1)\n",
    "            )\n",
    "            self.concat_conv = BasicConv(out_channels*2, out_channels, 1)\n",
    "        else:\n",
    "            self.split_conv0 = BasicConv(out_channels, out_channels//2, 1)\n",
    "            self.split_conv1 = BasicConv(out_channels, out_channels//2, 1)\n",
    "\n",
    "            self.blocks_conv = nn.Sequential(\n",
    "                *[Resblock(out_channels//2) for _ in range(num_blocks)],\n",
    "                BasicConv(out_channels//2, out_channels//2, 1)\n",
    "            )\n",
    "            self.concat_conv = BasicConv(out_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample_conv(x)\n",
    "\n",
    "        x0 = self.split_conv0(x)\n",
    "\n",
    "        x1 = self.split_conv1(x)\n",
    "        x1 = self.blocks_conv(x1)\n",
    "\n",
    "        x = torch.cat([x1, x0], dim=1)\n",
    "        x = self.concat_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CSPDarkNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(CSPDarkNet, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.conv1 = BasicConv(3, self.inplanes, kernel_size=3, stride=1)\n",
    "        self.feature_channels = [64, 128, 256, 512, 1024]\n",
    "\n",
    "        self.stages = nn.ModuleList([\n",
    "            Resblock_body(self.inplanes, self.feature_channels[0], layers[0], first=True),\n",
    "            Resblock_body(self.feature_channels[0], self.feature_channels[1], layers[1], first=False),\n",
    "            Resblock_body(self.feature_channels[1], self.feature_channels[2], layers[2], first=False),\n",
    "            Resblock_body(self.feature_channels[2], self.feature_channels[3], layers[3], first=False),\n",
    "            Resblock_body(self.feature_channels[3], self.feature_channels[4], layers[4], first=False)\n",
    "        ])\n",
    "\n",
    "        self.num_features = 1\n",
    "        # 进行权值初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.stages[0](x)\n",
    "        x = self.stages[1](x)\n",
    "        out3 = self.stages[2](x)\n",
    "        out4 = self.stages[3](out3)\n",
    "        out5 = self.stages[4](out4)\n",
    "\n",
    "        return out3, out4, out5\n",
    "\n",
    "def darknet53(pretrained, **kwargs):\n",
    "    model = CSPDarkNet([1, 2, 8, 8, 4])\n",
    "    if pretrained:\n",
    "        if isinstance(pretrained, str):\n",
    "            model.load_state_dict(torch.load(pretrained))\n",
    "        else:\n",
    "            raise Exception(\"darknet request a pretrained path. got [{}]\".format(pretrained))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1y2T0x7Xn1A"
   },
   "source": [
    "### net.yolo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clG-i7C9Xlyd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "# from nets.CSPdarknet import darknet53\n",
    "\n",
    "def conv2d(filter_in, filter_out, kernel_size, stride=1):\n",
    "    pad = (kernel_size - 1) // 2 if kernel_size else 0\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        (\"conv\", nn.Conv2d(filter_in, filter_out, kernel_size=kernel_size, stride=stride, padding=pad, bias=False)),\n",
    "        (\"bn\", nn.BatchNorm2d(filter_out)),\n",
    "        (\"relu\", nn.LeakyReLU(0.1)),\n",
    "    ]))\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   SPP结构，利用不同大小的池化核进行池化\n",
    "#   池化后堆叠\n",
    "#---------------------------------------------------#\n",
    "class SpatialPyramidPooling(nn.Module):\n",
    "    def __init__(self, pool_sizes=[5, 9, 13]):\n",
    "        super(SpatialPyramidPooling, self).__init__()\n",
    "\n",
    "        self.maxpools = nn.ModuleList([nn.MaxPool2d(pool_size, 1, pool_size//2) for pool_size in pool_sizes])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [maxpool(x) for maxpool in self.maxpools[::-1]]\n",
    "        features = torch.cat(features + [x], dim=1)\n",
    "\n",
    "        return features\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   卷积 + 上采样\n",
    "#---------------------------------------------------#\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Upsample, self).__init__()\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            conv2d(in_channels, out_channels, 1),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "\n",
    "    def forward(self, x,):\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   三次卷积块\n",
    "#---------------------------------------------------#\n",
    "def make_three_conv(filters_list, in_filters):\n",
    "    m = nn.Sequential(\n",
    "        conv2d(in_filters, filters_list[0], 1),\n",
    "        conv2d(filters_list[0], filters_list[1], 3),\n",
    "        conv2d(filters_list[1], filters_list[0], 1),\n",
    "    )\n",
    "    return m\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   五次卷积块\n",
    "#---------------------------------------------------#\n",
    "def make_five_conv(filters_list, in_filters):\n",
    "    m = nn.Sequential(\n",
    "        conv2d(in_filters, filters_list[0], 1),\n",
    "        conv2d(filters_list[0], filters_list[1], 3),\n",
    "        conv2d(filters_list[1], filters_list[0], 1),\n",
    "        conv2d(filters_list[0], filters_list[1], 3),\n",
    "        conv2d(filters_list[1], filters_list[0], 1),\n",
    "    )\n",
    "    return m\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   最后获得yolov4的输出\n",
    "#---------------------------------------------------#\n",
    "def yolo_head(filters_list, in_filters):\n",
    "    m = nn.Sequential(\n",
    "        conv2d(in_filters, filters_list[0], 3),\n",
    "        nn.Conv2d(filters_list[0], filters_list[1], 1),\n",
    "    )\n",
    "    return m\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   yolo_body\n",
    "#---------------------------------------------------#\n",
    "class YoloBody(nn.Module):\n",
    "    def __init__(self, num_anchors, num_classes):\n",
    "        super(YoloBody, self).__init__()\n",
    "        #  backbone\n",
    "        self.backbone = darknet53(None)\n",
    "\n",
    "        self.conv1 = make_three_conv([512,1024],1024)\n",
    "        self.SPP = SpatialPyramidPooling()\n",
    "        self.conv2 = make_three_conv([512,1024],2048)\n",
    "\n",
    "        self.upsample1 = Upsample(512,256)\n",
    "        self.conv_for_P4 = conv2d(512,256,1)\n",
    "        self.make_five_conv1 = make_five_conv([256, 512],512)\n",
    "\n",
    "        self.upsample2 = Upsample(256,128)\n",
    "        self.conv_for_P3 = conv2d(256,128,1)\n",
    "        self.make_five_conv2 = make_five_conv([128, 256],256)\n",
    "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
    "        # 4+1+num_classes\n",
    "        final_out_filter2 = num_anchors * (5 + num_classes)\n",
    "        self.yolo_head3 = yolo_head([256, final_out_filter2],128)\n",
    "\n",
    "        self.down_sample1 = conv2d(128,256,3,stride=2)\n",
    "        self.make_five_conv3 = make_five_conv([256, 512],512)\n",
    "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
    "        final_out_filter1 =  num_anchors * (5 + num_classes)\n",
    "        self.yolo_head2 = yolo_head([512, final_out_filter1],256)\n",
    "\n",
    "\n",
    "        self.down_sample2 = conv2d(256,512,3,stride=2)\n",
    "        self.make_five_conv4 = make_five_conv([512, 1024],1024)\n",
    "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
    "        final_out_filter0 =  num_anchors * (5 + num_classes)\n",
    "        self.yolo_head1 = yolo_head([1024, final_out_filter0],512)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  backbone\n",
    "        x2, x1, x0 = self.backbone(x)\n",
    "\n",
    "        P5 = self.conv1(x0)\n",
    "        P5 = self.SPP(P5)\n",
    "        P5 = self.conv2(P5)\n",
    "\n",
    "        P5_upsample = self.upsample1(P5)\n",
    "        P4 = self.conv_for_P4(x1)\n",
    "        P4 = torch.cat([P4,P5_upsample],axis=1)\n",
    "        P4 = self.make_five_conv1(P4)\n",
    "\n",
    "        P4_upsample = self.upsample2(P4)\n",
    "        P3 = self.conv_for_P3(x2)\n",
    "        P3 = torch.cat([P3,P4_upsample],axis=1)\n",
    "        P3 = self.make_five_conv2(P3)\n",
    "\n",
    "        P3_downsample = self.down_sample1(P3)\n",
    "        P4 = torch.cat([P3_downsample,P4],axis=1)\n",
    "        P4 = self.make_five_conv3(P4)\n",
    "\n",
    "        P4_downsample = self.down_sample2(P4)\n",
    "        P5 = torch.cat([P4_downsample,P5],axis=1)\n",
    "        P5 = self.make_five_conv4(P5)\n",
    "\n",
    "        out2 = self.yolo_head3(P3)\n",
    "        out1 = self.yolo_head2(P4)\n",
    "        out0 = self.yolo_head1(P5)\n",
    "\n",
    "        return out0, out1, out2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04yUu5eiYBI7"
   },
   "source": [
    "### utils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNBN0ATiYEkS"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DecodeBox(nn.Module):\n",
    "    def __init__(self, anchors, num_classes, img_size):\n",
    "        super(DecodeBox, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = len(anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.bbox_attrs = 5 + num_classes\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input为bs,3*(1+4+num_classes),13,13\n",
    "\n",
    "        # 一共多少张图片\n",
    "        batch_size = input.size(0)\n",
    "        # 13，13\n",
    "        input_height = input.size(2)\n",
    "        input_width = input.size(3)\n",
    "\n",
    "        # 计算步长\n",
    "        # 每一个特征点对应原来的图片上多少个像素点\n",
    "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
    "        # 416/13 = 32\n",
    "        stride_h = self.img_size[1] / input_height\n",
    "        stride_w = self.img_size[0] / input_width\n",
    "\n",
    "        # 把先验框的尺寸调整成特征层大小的形式\n",
    "        # 计算出先验框在特征层上对应的宽高\n",
    "        scaled_anchors = [(anchor_width / stride_w, anchor_height / stride_h) for anchor_width, anchor_height in self.anchors]\n",
    "\n",
    "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
    "        prediction = input.view(batch_size, self.num_anchors,\n",
    "                                self.bbox_attrs, input_height, input_width).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "        # 先验框的中心位置的调整参数\n",
    "        x = torch.sigmoid(prediction[..., 0])  \n",
    "        y = torch.sigmoid(prediction[..., 1])\n",
    "        # 先验框的宽高调整参数\n",
    "        w = prediction[..., 2]  # Width\n",
    "        h = prediction[..., 3]  # Height\n",
    "\n",
    "        # 获得置信度，是否有物体\n",
    "        conf = torch.sigmoid(prediction[..., 4])\n",
    "        # 种类置信度\n",
    "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
    "\n",
    "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
    "\n",
    "        # 生成网格，先验框中心，网格左上角 batch_size,3,13,13\n",
    "        grid_x = torch.linspace(0, input_width - 1, input_width).repeat(input_width, 1).repeat(\n",
    "            batch_size * self.num_anchors, 1, 1).view(x.shape).type(FloatTensor)\n",
    "        grid_y = torch.linspace(0, input_height - 1, input_height).repeat(input_height, 1).t().repeat(\n",
    "            batch_size * self.num_anchors, 1, 1).view(y.shape).type(FloatTensor)\n",
    "\n",
    "        # 生成先验框的宽高\n",
    "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
    "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
    "        anchor_w = anchor_w.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(w.shape)\n",
    "        anchor_h = anchor_h.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(h.shape)\n",
    "        \n",
    "        # 计算调整后的先验框中心与宽高\n",
    "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
    "        pred_boxes[..., 0] = x.data + grid_x\n",
    "        pred_boxes[..., 1] = y.data + grid_y\n",
    "        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n",
    "        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n",
    "\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot(121)\n",
    "        # if input_height==13:\n",
    "        #     plt.ylim(0,13)\n",
    "        #     plt.xlim(0,13)\n",
    "        # elif input_height==26:\n",
    "        #     plt.ylim(0,26)\n",
    "        #     plt.xlim(0,26)\n",
    "        # elif input_height==52:\n",
    "        #     plt.ylim(0,52)\n",
    "        #     plt.xlim(0,52)\n",
    "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
    "\n",
    "        # anchor_left = grid_x - anchor_w/2 \n",
    "        # anchor_top = grid_y - anchor_h/2 \n",
    "\n",
    "        # rect1 = plt.Rectangle([anchor_left[0,0,5,5],anchor_top[0,0,5,5]],anchor_w[0,0,5,5],anchor_h[0,0,5,5],color=\"r\",fill=False)\n",
    "        # rect2 = plt.Rectangle([anchor_left[0,1,5,5],anchor_top[0,1,5,5]],anchor_w[0,1,5,5],anchor_h[0,1,5,5],color=\"r\",fill=False)\n",
    "        # rect3 = plt.Rectangle([anchor_left[0,2,5,5],anchor_top[0,2,5,5]],anchor_w[0,2,5,5],anchor_h[0,2,5,5],color=\"r\",fill=False)\n",
    "\n",
    "        # ax.add_patch(rect1)\n",
    "        # ax.add_patch(rect2)\n",
    "        # ax.add_patch(rect3)\n",
    "\n",
    "        # ax = fig.add_subplot(122)\n",
    "        # if input_height==13:\n",
    "        #     plt.ylim(0,13)\n",
    "        #     plt.xlim(0,13)\n",
    "        # elif input_height==26:\n",
    "        #     plt.ylim(0,26)\n",
    "        #     plt.xlim(0,26)\n",
    "        # elif input_height==52:\n",
    "        #     plt.ylim(0,52)\n",
    "        #     plt.xlim(0,52)\n",
    "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
    "        # plt.scatter(pred_boxes[0,:,5,5,0].cpu(),pred_boxes[0,:,5,5,1].cpu(),c='r')\n",
    "\n",
    "        # pre_left = pred_boxes[...,0] - pred_boxes[...,2]/2 \n",
    "        # pre_top = pred_boxes[...,1] - pred_boxes[...,3]/2 \n",
    "\n",
    "        # rect1 = plt.Rectangle([pre_left[0,0,5,5],pre_top[0,0,5,5]],pred_boxes[0,0,5,5,2],pred_boxes[0,0,5,5,3],color=\"r\",fill=False)\n",
    "        # rect2 = plt.Rectangle([pre_left[0,1,5,5],pre_top[0,1,5,5]],pred_boxes[0,1,5,5,2],pred_boxes[0,1,5,5,3],color=\"r\",fill=False)\n",
    "        # rect3 = plt.Rectangle([pre_left[0,2,5,5],pre_top[0,2,5,5]],pred_boxes[0,2,5,5,2],pred_boxes[0,2,5,5,3],color=\"r\",fill=False)\n",
    "\n",
    "        # ax.add_patch(rect1)\n",
    "        # ax.add_patch(rect2)\n",
    "        # ax.add_patch(rect3)\n",
    "\n",
    "        # plt.show()\n",
    "        # 用于将输出调整为相对于416x416的大小\n",
    "        _scale = torch.Tensor([stride_w, stride_h] * 2).type(FloatTensor)\n",
    "        output = torch.cat((pred_boxes.view(batch_size, -1, 4) * _scale,\n",
    "                            conf.view(batch_size, -1, 1), pred_cls.view(batch_size, -1, self.num_classes)), -1)\n",
    "        return output.data\n",
    "        \n",
    "def letterbox_image(image, size):\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def yolo_correct_boxes(top, left, bottom, right, input_shape, image_shape):\n",
    "    new_shape = image_shape*np.min(input_shape/image_shape)\n",
    "\n",
    "    offset = (input_shape-new_shape)/2./input_shape\n",
    "    scale = input_shape/new_shape\n",
    "\n",
    "    box_yx = np.concatenate(((top+bottom)/2,(left+right)/2),axis=-1)/input_shape\n",
    "    box_hw = np.concatenate((bottom-top,right-left),axis=-1)/input_shape\n",
    "\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes =  np.concatenate([\n",
    "        box_mins[:, 0:1],\n",
    "        box_mins[:, 1:2],\n",
    "        box_maxes[:, 0:1],\n",
    "        box_maxes[:, 1:2]\n",
    "    ],axis=-1)\n",
    "    print(np.shape(boxes))\n",
    "    boxes *= np.concatenate([image_shape, image_shape],axis=-1)\n",
    "    return boxes\n",
    "\n",
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    \"\"\"\n",
    "        计算IOU\n",
    "    \"\"\"\n",
    "    if not x1y1x2y2:\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "    else:\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * \\\n",
    "                 torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
    "                 \n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def non_max_suppression(prediction, num_classes, conf_thres=0.5, nms_thres=0.4):\n",
    "    # 求左上角和右下角\n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
    "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
    "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
    "\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    for image_i, image_pred in enumerate(prediction):\n",
    "        # 利用置信度进行第一轮筛选\n",
    "        conf_mask = (image_pred[:, 4] >= conf_thres).squeeze()\n",
    "        image_pred = image_pred[conf_mask]\n",
    "\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "\n",
    "        # 获得种类及其置信度\n",
    "        class_conf, class_pred = torch.max(image_pred[:, 5:5 + num_classes], 1, keepdim=True)\n",
    "\n",
    "        # 获得的内容为(x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
    "        detections = torch.cat((image_pred[:, :5], class_conf.float(), class_pred.float()), 1)\n",
    "\n",
    "        # 获得种类\n",
    "        unique_labels = detections[:, -1].cpu().unique()\n",
    "\n",
    "        if prediction.is_cuda:\n",
    "            unique_labels = unique_labels.cuda()\n",
    "\n",
    "        for c in unique_labels:\n",
    "            # 获得某一类初步筛选后全部的预测结果\n",
    "            detections_class = detections[detections[:, -1] == c]\n",
    "            # 按照存在物体的置信度排序\n",
    "            _, conf_sort_index = torch.sort(detections_class[:, 4], descending=True)\n",
    "            detections_class = detections_class[conf_sort_index]\n",
    "            # 进行非极大抑制\n",
    "            max_detections = []\n",
    "            while detections_class.size(0):\n",
    "                # 取出这一类置信度最高的，一步一步往下判断，判断重合程度是否大于nms_thres，如果是则去除掉\n",
    "                max_detections.append(detections_class[0].unsqueeze(0))\n",
    "                if len(detections_class) == 1:\n",
    "                    break\n",
    "                ious = bbox_iou(max_detections[-1], detections_class[1:])\n",
    "                detections_class = detections_class[1:][ious < nms_thres]\n",
    "            # 堆叠\n",
    "            max_detections = torch.cat(max_detections).data\n",
    "            # Add max detections to outputs\n",
    "            output[image_i] = max_detections if output[image_i] is None else torch.cat(\n",
    "                (output[image_i], max_detections))\n",
    "\n",
    "    return output\n",
    "\n",
    "def merge_bboxes(bboxes, cutx, cuty):\n",
    "    merge_bbox = []\n",
    "    for i in range(len(bboxes)):\n",
    "        for box in bboxes[i]:\n",
    "            tmp_box = []\n",
    "            x1,y1,x2,y2 = box[0], box[1], box[2], box[3]\n",
    "\n",
    "            if i == 0:\n",
    "                if y1 > cuty or x1 > cutx:\n",
    "                    continue\n",
    "                if y2 >= cuty and y1 <= cuty:\n",
    "                    y2 = cuty\n",
    "                    if y2-y1 < 5:\n",
    "                        continue\n",
    "                if x2 >= cutx and x1 <= cutx:\n",
    "                    x2 = cutx\n",
    "                    if x2-x1 < 5:\n",
    "                        continue\n",
    "                \n",
    "            if i == 1:\n",
    "                if y2 < cuty or x1 > cutx:\n",
    "                    continue\n",
    "\n",
    "                if y2 >= cuty and y1 <= cuty:\n",
    "                    y1 = cuty\n",
    "                    if y2-y1 < 5:\n",
    "                        continue\n",
    "                \n",
    "                if x2 >= cutx and x1 <= cutx:\n",
    "                    x2 = cutx\n",
    "                    if x2-x1 < 5:\n",
    "                        continue\n",
    "\n",
    "            if i == 2:\n",
    "                if y2 < cuty or x2 < cutx:\n",
    "                    continue\n",
    "\n",
    "                if y2 >= cuty and y1 <= cuty:\n",
    "                    y1 = cuty\n",
    "                    if y2-y1 < 5:\n",
    "                        continue\n",
    "\n",
    "                if x2 >= cutx and x1 <= cutx:\n",
    "                    x1 = cutx\n",
    "                    if x2-x1 < 5:\n",
    "                        continue\n",
    "\n",
    "            if i == 3:\n",
    "                if y1 > cuty or x2 < cutx:\n",
    "                    continue\n",
    "\n",
    "                if y2 >= cuty and y1 <= cuty:\n",
    "                    y2 = cuty\n",
    "                    if y2-y1 < 5:\n",
    "                        continue\n",
    "\n",
    "                if x2 >= cutx and x1 <= cutx:\n",
    "                    x1 = cutx\n",
    "                    if x2-x1 < 5:\n",
    "                        continue\n",
    "\n",
    "            tmp_box.append(x1)\n",
    "            tmp_box.append(y1)\n",
    "            tmp_box.append(x2)\n",
    "            tmp_box.append(y2)\n",
    "            tmp_box.append(box[-1])\n",
    "            merge_bbox.append(tmp_box)\n",
    "    return merge_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZp4q7ODX5H7"
   },
   "source": [
    "### nets.yolo_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSULB0IkX6NO"
   },
   "outputs": [],
   "source": [
    "  \n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "from PIL import Image\n",
    "# from utils.utils import bbox_iou, merge_bboxes\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   平滑标签\n",
    "#---------------------------------------------------#\n",
    "def smooth_labels(y_true, label_smoothing,num_classes):\n",
    "    return y_true * (1.0 - label_smoothing) + label_smoothing / num_classes\n",
    "\n",
    "def box_ciou(b1, b2):\n",
    "    \"\"\"\n",
    "    输入为：\n",
    "    ----------\n",
    "    b1: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
    "    b2: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
    "\n",
    "    返回为：\n",
    "    -------\n",
    "    ciou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n",
    "    \"\"\"\n",
    "    # 求出预测框左上角右下角\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "    # 求出真实框左上角右下角\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    # 求真实框和预测框所有的iou\n",
    "    intersect_mins = torch.max(b1_mins, b2_mins)\n",
    "    intersect_maxes = torch.min(b1_maxes, b2_maxes)\n",
    "    intersect_wh = torch.max(intersect_maxes - intersect_mins, torch.zeros_like(intersect_maxes))\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    union_area = b1_area + b2_area - intersect_area\n",
    "    iou = intersect_area / torch.clamp(union_area,min = 1e-6)\n",
    "\n",
    "    # 计算中心的差距\n",
    "    center_distance = torch.sum(torch.pow((b1_xy - b2_xy), 2), axis=-1)\n",
    "    \n",
    "    # 找到包裹两个框的最小框的左上角和右下角\n",
    "    enclose_mins = torch.min(b1_mins, b2_mins)\n",
    "    enclose_maxes = torch.max(b1_maxes, b2_maxes)\n",
    "    enclose_wh = torch.max(enclose_maxes - enclose_mins, torch.zeros_like(intersect_maxes))\n",
    "    # 计算对角线距离\n",
    "    enclose_diagonal = torch.sum(torch.pow(enclose_wh,2), axis=-1)\n",
    "    ciou = iou - 1.0 * (center_distance) / torch.clamp(enclose_diagonal,min = 1e-6)\n",
    "    \n",
    "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(b1_wh[..., 0]/torch.clamp(b1_wh[..., 1],min = 1e-6)) - torch.atan(b2_wh[..., 0]/torch.clamp(b2_wh[..., 1],min = 1e-6))), 2)\n",
    "    alpha = v / torch.clamp((1.0 - iou + v),min=1e-6)\n",
    "    ciou = ciou - alpha * v\n",
    "    return ciou\n",
    "  \n",
    "def clip_by_tensor(t,t_min,t_max):\n",
    "    t=t.float()\n",
    "    result = (t >= t_min).float() * t + (t < t_min).float() * t_min\n",
    "    result = (result <= t_max).float() * result + (result > t_max).float() * t_max\n",
    "    return result\n",
    "\n",
    "def MSELoss(pred,target):\n",
    "    return (pred-target)**2\n",
    "\n",
    "def BCELoss(pred,target):\n",
    "    epsilon = 1e-7\n",
    "    pred = clip_by_tensor(pred, epsilon, 1.0 - epsilon)\n",
    "    output = -target * torch.log(pred) - (1.0 - target) * torch.log(1.0 - pred)\n",
    "    return output\n",
    "\n",
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, anchors, num_classes, img_size, label_smooth=0, cuda=True):\n",
    "        super(YOLOLoss, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = len(anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.bbox_attrs = 5 + num_classes\n",
    "        self.img_size = img_size\n",
    "        self.feature_length = [img_size[0]//32,img_size[0]//16,img_size[0]//8]\n",
    "        self.label_smooth = label_smooth\n",
    "\n",
    "        self.ignore_threshold = 0.5\n",
    "        self.lambda_conf = 1.0\n",
    "        self.lambda_cls = 1.0\n",
    "        self.lambda_loc = 1.0\n",
    "        self.cuda = cuda\n",
    "\n",
    "    def forward(self, input, targets=None):\n",
    "        # input为bs,3*(5+num_classes),13,13\n",
    "        \n",
    "        # 一共多少张图片\n",
    "        bs = input.size(0)\n",
    "        # 特征层的高\n",
    "        in_h = input.size(2)\n",
    "        # 特征层的宽\n",
    "        in_w = input.size(3)\n",
    "\n",
    "        # 计算步长\n",
    "        # 每一个特征点对应原来的图片上多少个像素点\n",
    "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
    "        stride_h = self.img_size[1] / in_h\n",
    "        stride_w = self.img_size[0] / in_w\n",
    "\n",
    "        # 把先验框的尺寸调整成特征层大小的形式\n",
    "        # 计算出先验框在特征层上对应的宽高\n",
    "        scaled_anchors = [(a_w / stride_w, a_h / stride_h) for a_w, a_h in self.anchors]\n",
    "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
    "        prediction = input.view(bs, int(self.num_anchors/3),\n",
    "                                self.bbox_attrs, in_h, in_w).permute(0, 1, 3, 4, 2).contiguous()\n",
    "        \n",
    "        # 对prediction预测进行调整\n",
    "        conf = torch.sigmoid(prediction[..., 4])  # Conf\n",
    "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
    "\n",
    "        # 找到哪些先验框内部包含物体\n",
    "        mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y = self.get_target(targets, scaled_anchors,in_w, in_h,self.ignore_threshold)\n",
    "\n",
    "        noobj_mask, pred_boxes_for_ciou = self.get_ignore(prediction, targets, scaled_anchors, in_w, in_h, noobj_mask)\n",
    "\n",
    "        if self.cuda:\n",
    "            mask, noobj_mask = mask.cuda(), noobj_mask.cuda()\n",
    "            box_loss_scale_x, box_loss_scale_y= box_loss_scale_x.cuda(), box_loss_scale_y.cuda()\n",
    "            tconf, tcls = tconf.cuda(), tcls.cuda()\n",
    "            pred_boxes_for_ciou = pred_boxes_for_ciou.cuda()\n",
    "            t_box = t_box.cuda()\n",
    "\n",
    "        box_loss_scale = 2-box_loss_scale_x*box_loss_scale_y\n",
    "        #  losses.\n",
    "        ciou = (1 - box_ciou( pred_boxes_for_ciou[mask.bool()], t_box[mask.bool()]))* box_loss_scale[mask.bool()]\n",
    "\n",
    "        loss_loc = torch.sum(ciou / bs)\n",
    "        loss_conf = torch.sum(BCELoss(conf, mask) * mask / bs) + \\\n",
    "                    torch.sum(BCELoss(conf, mask) * noobj_mask / bs)\n",
    "                    \n",
    "        # print(smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))\n",
    "        loss_cls = torch.sum(BCELoss(pred_cls[mask == 1], smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))/bs)\n",
    "        # print(loss_loc,loss_conf,loss_cls)\n",
    "        loss = loss_conf * self.lambda_conf + loss_cls * self.lambda_cls + loss_loc * self.lambda_loc\n",
    "        return loss, loss_conf.item(), loss_cls.item(), loss_loc.item()\n",
    "\n",
    "    def get_target(self, target, anchors, in_w, in_h, ignore_threshold):\n",
    "        # 计算一共有多少张图片\n",
    "        bs = len(target)\n",
    "        # 获得先验框\n",
    "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
    "        subtract_index = [0,3,6][self.feature_length.index(in_w)]\n",
    "        # 创建全是0或者全是1的阵列\n",
    "        mask = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        noobj_mask = torch.ones(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "\n",
    "        tx = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        ty = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        tw = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        th = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        t_box = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, 4, requires_grad=False)\n",
    "        tconf = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        tcls = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, self.num_classes, requires_grad=False)\n",
    "\n",
    "        box_loss_scale_x = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        box_loss_scale_y = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
    "        for b in range(bs):\n",
    "            for t in range(target[b].shape[0]):\n",
    "                # 计算出在特征层上的点位\n",
    "                gx = target[b][t, 0] * in_w\n",
    "                gy = target[b][t, 1] * in_h\n",
    "                \n",
    "                gw = target[b][t, 2] * in_w\n",
    "                gh = target[b][t, 3] * in_h\n",
    "\n",
    "                # 计算出属于哪个网格\n",
    "                gi = int(gx)\n",
    "                gj = int(gy)\n",
    "\n",
    "                # 计算真实框的位置\n",
    "                gt_box = torch.FloatTensor(np.array([0, 0, gw, gh])).unsqueeze(0)\n",
    "                \n",
    "                # 计算出所有先验框的位置\n",
    "                anchor_shapes = torch.FloatTensor(np.concatenate((np.zeros((self.num_anchors, 2)),\n",
    "                                                                  np.array(anchors)), 1))\n",
    "                # 计算重合程度\n",
    "                anch_ious = bbox_iou(gt_box, anchor_shapes)\n",
    "               \n",
    "                # Find the best matching anchor box\n",
    "                best_n = np.argmax(anch_ious)\n",
    "                if best_n not in anchor_index:\n",
    "                    continue\n",
    "                # Masks\n",
    "                if (gj < in_h) and (gi < in_w):\n",
    "                    best_n = best_n - subtract_index\n",
    "                    # 判定哪些先验框内部真实的存在物体\n",
    "                    noobj_mask[b, best_n, gj, gi] = 0\n",
    "                    mask[b, best_n, gj, gi] = 1\n",
    "                    # 计算先验框中心调整参数\n",
    "                    tx[b, best_n, gj, gi] = gx\n",
    "                    ty[b, best_n, gj, gi] = gy\n",
    "                    # 计算先验框宽高调整参数\n",
    "                    tw[b, best_n, gj, gi] = gw\n",
    "                    th[b, best_n, gj, gi] = gh\n",
    "                    # 用于获得xywh的比例\n",
    "                    box_loss_scale_x[b, best_n, gj, gi] = target[b][t, 2]\n",
    "                    box_loss_scale_y[b, best_n, gj, gi] = target[b][t, 3]\n",
    "                    # 物体置信度\n",
    "                    tconf[b, best_n, gj, gi] = 1\n",
    "                    # 种类\n",
    "#                     print('#'*50)\n",
    "#                     print(tcls.shape)\n",
    "#                     print(b, best_n, gj, gi, int(target[b][t, 4]))\n",
    "                    tcls[b, best_n, gj, gi, int(target[b][t, 4])] = 1\n",
    "                else:\n",
    "                    print('Step {0} out of bound'.format(b))\n",
    "                    print('gj: {0}, height: {1} | gi: {2}, width: {3}'.format(gj, in_h, gi, in_w))\n",
    "                    continue\n",
    "        t_box[...,0] = tx\n",
    "        t_box[...,1] = ty\n",
    "        t_box[...,2] = tw\n",
    "        t_box[...,3] = th\n",
    "        return mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y\n",
    "\n",
    "    def get_ignore(self,prediction,target,scaled_anchors,in_w, in_h,noobj_mask):\n",
    "        bs = len(target)\n",
    "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
    "        scaled_anchors = np.array(scaled_anchors)[anchor_index]\n",
    "        # 先验框的中心位置的调整参数\n",
    "        x = torch.sigmoid(prediction[..., 0])  \n",
    "        y = torch.sigmoid(prediction[..., 1])\n",
    "        # 先验框的宽高调整参数\n",
    "        w = prediction[..., 2]  # Width\n",
    "        h = prediction[..., 3]  # Height\n",
    "\n",
    "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
    "\n",
    "        # 生成网格，先验框中心，网格左上角\n",
    "        grid_x = torch.linspace(0, in_w - 1, in_w).repeat(in_w, 1).repeat(\n",
    "            int(bs*self.num_anchors/3), 1, 1).view(x.shape).type(FloatTensor)\n",
    "        grid_y = torch.linspace(0, in_h - 1, in_h).repeat(in_h, 1).t().repeat(\n",
    "            int(bs*self.num_anchors/3), 1, 1).view(y.shape).type(FloatTensor)\n",
    "\n",
    "        # 生成先验框的宽高\n",
    "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
    "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
    "        \n",
    "        anchor_w = anchor_w.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(w.shape)\n",
    "        anchor_h = anchor_h.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(h.shape)\n",
    "        \n",
    "        # 计算调整后的先验框中心与宽高\n",
    "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
    "        pred_boxes[..., 0] = x + grid_x\n",
    "        pred_boxes[..., 1] = y + grid_y\n",
    "        pred_boxes[..., 2] = torch.exp(w) * anchor_w\n",
    "        pred_boxes[..., 3] = torch.exp(h) * anchor_h\n",
    "        for i in range(bs):\n",
    "            pred_boxes_for_ignore = pred_boxes[i]\n",
    "            pred_boxes_for_ignore = pred_boxes_for_ignore.view(-1, 4)\n",
    "\n",
    "            for t in range(target[i].shape[0]):\n",
    "                gx = target[i][t, 0] * in_w\n",
    "                gy = target[i][t, 1] * in_h\n",
    "                gw = target[i][t, 2] * in_w\n",
    "                gh = target[i][t, 3] * in_h\n",
    "                gt_box = torch.FloatTensor(np.array([gx, gy, gw, gh])).unsqueeze(0).type(FloatTensor)\n",
    "\n",
    "                anch_ious = bbox_iou(gt_box, pred_boxes_for_ignore, x1y1x2y2=False)\n",
    "                anch_ious = anch_ious.view(pred_boxes[i].size()[:3])\n",
    "                noobj_mask[i][anch_ious>self.ignore_threshold] = 0\n",
    "        return noobj_mask, pred_boxes\n",
    "\n",
    "\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    def __init__(self,batch_size,\n",
    "                 train_lines, image_size,\n",
    "                 ):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.train_lines = train_lines\n",
    "        self.train_batches = len(train_lines)\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def get_random_data(self, annotation_line, input_shape, jitter=.3, hue=.1, sat=1.5, val=1.5):\n",
    "        '''r实时数据增强的随机预处理'''\n",
    "        line = annotation_line.split()\n",
    "#         line[0] = line[0] + ' ' + line[1]\n",
    "        del line[1]\n",
    "        # print(line)\n",
    "        image = Image.open(line[0])\n",
    "        iw, ih = image.size\n",
    "        h, w = input_shape\n",
    "        box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "        # resize image\n",
    "        new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "        scale = rand(.25, 2)\n",
    "        if new_ar < 1:\n",
    "            nh = int(scale*h)\n",
    "            nw = int(nh*new_ar)\n",
    "        else:\n",
    "            nw = int(scale*w)\n",
    "            nh = int(nw/new_ar)\n",
    "        image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "        # place image\n",
    "        dx = int(rand(0, w-nw))\n",
    "        dy = int(rand(0, h-nh))\n",
    "        new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "        new_image.paste(image, (dx, dy))\n",
    "        image = new_image\n",
    "\n",
    "        # flip image or not\n",
    "        flip = rand()<.5\n",
    "        if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        # distort image\n",
    "        hue = rand(-hue, hue)\n",
    "        sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "        val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "        x = rgb_to_hsv(np.array(image)/255.)\n",
    "        x[..., 0] += hue\n",
    "        x[..., 0][x[..., 0]>1] -= 1\n",
    "        x[..., 0][x[..., 0]<0] += 1\n",
    "        x[..., 1] *= sat\n",
    "        x[..., 2] *= val\n",
    "        x[x>1] = 1\n",
    "        x[x<0] = 0\n",
    "        image_data = hsv_to_rgb(x)*255 # numpy array, 0 to 1\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((len(box),5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "            if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "            box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "            box[:, 2][box[:, 2]>w] = w\n",
    "            box[:, 3][box[:, 3]>h] = h\n",
    "            box_w = box[:, 2] - box[:, 0]\n",
    "            box_h = box[:, 3] - box[:, 1]\n",
    "            box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "            box_data = np.zeros((len(box),5))\n",
    "            box_data[:len(box)] = box\n",
    "        if len(box) == 0:\n",
    "            return image_data, []\n",
    "\n",
    "        if (box_data[:,:4]>0).any():\n",
    "            return image_data, box_data\n",
    "        else:\n",
    "            return image_data, []\n",
    "\n",
    "    def get_random_data_with_Mosaic(self, annotation_line, input_shape, hue=.1, sat=1.5, val=1.5):\n",
    "        '''random preprocessing for real-time data augmentation'''\n",
    "        h, w = input_shape\n",
    "        min_offset_x = 0.4\n",
    "        min_offset_y = 0.4\n",
    "        scale_low = 1-min(min_offset_x,min_offset_y)\n",
    "        scale_high = scale_low+0.2\n",
    "\n",
    "        image_datas = [] \n",
    "        box_datas = []\n",
    "        index = 0\n",
    "\n",
    "        place_x = [0,0,int(w*min_offset_x),int(w*min_offset_x)]\n",
    "        place_y = [0,int(h*min_offset_y),int(w*min_offset_y),0]\n",
    "        for line in annotation_line:\n",
    "            # 每一行进行分割\n",
    "            line_content = line.split(' ')\n",
    "#             line_content[0] = line_content[0] + ' ' + line_content[1]\n",
    "#             del line_content[1]\n",
    "            # 打开图片\n",
    "            image = Image.open(line_content[0])\n",
    "            image = image.convert(\"RGB\") \n",
    "            # 图片的大小\n",
    "            iw, ih = image.size\n",
    "            # 保存框的位置\n",
    "            box = np.array([np.array(list(map(int,box.split(',')))) for box in line_content[1:]])\n",
    "            \n",
    "            # 是否翻转图片\n",
    "            flip = rand()<.5\n",
    "            if flip and len(box)>0:\n",
    "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                box[:, [0,2]] = iw - box[:, [2,0]]\n",
    "\n",
    "            # 对输入进来的图片进行缩放\n",
    "            new_ar = w/h\n",
    "            scale = rand(scale_low, scale_high)\n",
    "            if new_ar < 1:\n",
    "                nh = int(scale*h)\n",
    "                nw = int(nh*new_ar)\n",
    "            else:\n",
    "                nw = int(scale*w)\n",
    "                nh = int(nw/new_ar)\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "            # 进行色域变换\n",
    "            hue = rand(-hue, hue)\n",
    "            sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "            val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "            x = rgb_to_hsv(np.array(image)/255.)\n",
    "            x[..., 0] += hue\n",
    "            x[..., 0][x[..., 0]>1] -= 1\n",
    "            x[..., 0][x[..., 0]<0] += 1\n",
    "            x[..., 1] *= sat\n",
    "            x[..., 2] *= val\n",
    "            x[x>1] = 1\n",
    "            x[x<0] = 0\n",
    "            image = hsv_to_rgb(x)\n",
    "\n",
    "            image = Image.fromarray((image*255).astype(np.uint8))\n",
    "            # 将图片进行放置，分别对应四张分割图片的位置\n",
    "            dx = place_x[index]\n",
    "            dy = place_y[index]\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)\n",
    "\n",
    "            \n",
    "            index = index + 1\n",
    "            box_data = []\n",
    "            # 对box进行重新处理\n",
    "            if len(box)>0:\n",
    "                np.random.shuffle(box)\n",
    "                box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "                box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "                box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "                box[:, 2][box[:, 2]>w] = w\n",
    "                box[:, 3][box[:, 3]>h] = h\n",
    "                box_w = box[:, 2] - box[:, 0]\n",
    "                box_h = box[:, 3] - box[:, 1]\n",
    "                box = box[np.logical_and(box_w>1, box_h>1)]\n",
    "                box_data = np.zeros((len(box),5))\n",
    "                box_data[:len(box)] = box\n",
    "            \n",
    "            image_datas.append(image_data)\n",
    "            box_datas.append(box_data)\n",
    "\n",
    "        # 将图片分割，放在一起\n",
    "        cutx = np.random.randint(int(w*min_offset_x), int(w*(1 - min_offset_x)))\n",
    "        cuty = np.random.randint(int(h*min_offset_y), int(h*(1 - min_offset_y)))\n",
    "\n",
    "        new_image = np.zeros([h,w,3])\n",
    "        new_image[:cuty, :cutx, :] = image_datas[0][:cuty, :cutx, :]\n",
    "        new_image[cuty:, :cutx, :] = image_datas[1][cuty:, :cutx, :]\n",
    "        new_image[cuty:, cutx:, :] = image_datas[2][cuty:, cutx:, :]\n",
    "        new_image[:cuty, cutx:, :] = image_datas[3][:cuty, cutx:, :]\n",
    "\n",
    "        # 对框进行进一步的处理\n",
    "        new_boxes = np.array(merge_bboxes(box_datas, cutx, cuty))\n",
    "\n",
    "        if len(new_boxes) == 0:\n",
    "            return new_image, []\n",
    "        if (new_boxes[:,:4]>0).any():\n",
    "            return new_image, new_boxes\n",
    "        else:\n",
    "            return new_image, []\n",
    "\n",
    "    def generate(self, train = True, mosaic = True):\n",
    "        while True:\n",
    "            shuffle(self.train_lines)\n",
    "            lines = self.train_lines\n",
    "            inputs = []\n",
    "            targets = []\n",
    "            flag = True\n",
    "            n = len(lines)\n",
    "            for i in range(len(lines)):\n",
    "                if mosaic == True:\n",
    "                    if flag and (i+4) < n:\n",
    "                        img,y = self.get_random_data_with_Mosaic(lines[i:i+4], self.image_size[0:2])\n",
    "                        i = (i+4) % n\n",
    "                    else:\n",
    "                        img,y = self.get_random_data(lines[i], self.image_size[0:2])\n",
    "                        i = (i+1) % n\n",
    "                    flag = bool(1-flag)\n",
    "                else:\n",
    "                    img,y = self.get_random_data(lines[i], self.image_size[0:2])\n",
    "                    i = (i+1) % n\n",
    "                if len(y)==0:\n",
    "                    continue\n",
    "                boxes = np.array(y[:,:4],dtype=np.float32)\n",
    "                boxes[:,0] = boxes[:,0]/self.image_size[1]\n",
    "                boxes[:,1] = boxes[:,1]/self.image_size[0]\n",
    "                boxes[:,2] = boxes[:,2]/self.image_size[1]\n",
    "                boxes[:,3] = boxes[:,3]/self.image_size[0]\n",
    "\n",
    "                boxes = np.maximum(np.minimum(boxes,1),0)\n",
    "                boxes[:,2] = boxes[:,2] - boxes[:,0]\n",
    "                boxes[:,3] = boxes[:,3] - boxes[:,1]\n",
    "  \n",
    "                boxes[:,0] = boxes[:,0] + boxes[:,2]/2\n",
    "                boxes[:,1] = boxes[:,1] + boxes[:,3]/2\n",
    "                y = np.concatenate([boxes,y[:,-1:]],axis=-1)\n",
    "                img = np.array(img,dtype = np.float32)\n",
    "\n",
    "                inputs.append(np.transpose(img/255.0,(2,0,1)))                \n",
    "                targets.append(y)\n",
    "                if len(targets) == self.batch_size:\n",
    "                    tmp_inp = np.array(inputs)\n",
    "                    tmp_targets = np.array(targets)\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    yield tmp_inp, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3LR1kbRWfLr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "# from nets.yolo4 import YoloBody\n",
    "# from nets.yolo_training import YOLOLoss, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GURw3fNiWfLv"
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------#\n",
    "#   获得类和先验框\n",
    "#---------------------------------------------------#\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape([-1,3,2])[::-1,:,:]\n",
    "\n",
    "\n",
    "#---------------------------------------------------#\n",
    "#   训练一个epoch\n",
    "#---------------------------------------------------#\n",
    "def fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen,genval, Epoch, cuda, optimizer, lr_scheduler):\n",
    "    total_loss = 0\n",
    "    val_loss = 0\n",
    "    print('\\n' + '-' * 10 + 'Train one epoch.' + '-' * 10)\n",
    "    print('Epoch:'+ str(epoch+1) + '/' + str(Epoch))\n",
    "    print('Start Training.')\n",
    "    net.train()\n",
    "    for iteration in range(epoch_size):\n",
    "        start_time = time.time()\n",
    "        images, targets = next(gen)\n",
    "        with torch.no_grad():\n",
    "            if cuda:\n",
    "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor)).cuda()\n",
    "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
    "            else:\n",
    "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor))\n",
    "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        losses = []\n",
    "        for i in range(3):\n",
    "            loss_item = yolo_losses[i](outputs[i], targets)\n",
    "            losses.append(loss_item[0])\n",
    "        loss = sum(losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        waste_time = time.time() - start_time\n",
    "        if iteration == 0 or (iteration+1) % 10 == 0:\n",
    "            print('step:' + str(iteration+1) + '/' + str(epoch_size) + ' || Total Loss: %.4f || %.4fs/step' % (total_loss/(iteration+1), waste_time))\n",
    "    print('Finish Training.')\n",
    "    '''        \n",
    "    print('Start Validation.')\n",
    "    net.eval()\n",
    "    for iteration in range(epoch_size_val):\n",
    "        images_val, targets_val = next(genval)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if cuda:\n",
    "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor)).cuda()\n",
    "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
    "            else:\n",
    "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor))\n",
    "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images_val)\n",
    "            losses = []\n",
    "            for i in range(3):\n",
    "                loss_item = yolo_losses[i](outputs[i], targets_val)\n",
    "                losses.append(loss_item[0])\n",
    "            loss = sum(losses)\n",
    "            val_loss += loss\n",
    "    print('Finish Validation')\n",
    "    '''\n",
    "    print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)))\n",
    "    \n",
    "    return total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxz15R--WfLx"
   },
   "outputs": [],
   "source": [
    "#-------------------------------#\n",
    "#   输入的shape大小\n",
    "#   显存比较小可以使用416x416\n",
    "#   显存比较大可以使用608x608\n",
    "#-------------------------------#\n",
    "#input_shape = (416,416)\n",
    "input_shape = (608, 608)\n",
    "\n",
    "#-------------------------------#\n",
    "#   tricks的使用设置\n",
    "#-------------------------------#\n",
    "Cosine_lr = True\n",
    "mosaic = True\n",
    "# 用于设定是否使用cuda\n",
    "Cuda = True\n",
    "smoooth_label = 0.03\n",
    "\n",
    "#-------------------------------#\n",
    "#   获得训练集和验证集的annotations\n",
    "#   \n",
    "#-------------------------------#\n",
    "train_annotation_path = 'model_data/train_bita.txt'\n",
    "val_annotation_path = 'model_data/val_bita.txt'\n",
    "\n",
    "#-------------------------------#\n",
    "#   获得先验框和类\n",
    "#-------------------------------#\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "classes_path = 'model_data/mask_classes.txt'   \n",
    "class_names = get_classes(classes_path)\n",
    "anchors = get_anchors(anchors_path)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15730,
     "status": "ok",
     "timestamp": 1592099729279,
     "user": {
      "displayName": "子豪盛",
      "photoUrl": "",
      "userId": "05777601522634171836"
     },
     "user_tz": -480
    },
    "id": "9SCHYBk7WfL0",
    "outputId": "e0fb878a-45de-4656-ae12-cb20060b94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model weights.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "model = YoloBody(len(anchors[0]), num_classes)\n",
    "#model_path = \"model_data/yolov4_coco_pretrained_weights.pth\"\n",
    "model_path = \"/data/zihaosh/hw2_pretrain/yolov4_coco_pretrained_weights.pth\"\n",
    "# 加快模型训练的效率\n",
    "print('Loading pretrained model weights.')\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = torch.load(model_path)\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "print('Finished!')\n",
    "\n",
    "if Cuda:\n",
    "    net = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    net = net.cuda()\n",
    "\n",
    "# 建立loss函数\n",
    "yolo_losses = []\n",
    "for i in range(3):\n",
    "    yolo_losses.append(YOLOLoss(np.reshape(anchors, [-1,2]), num_classes, \\\n",
    "                                (input_shape[1], input_shape[0]), smoooth_label, Cuda))\n",
    "# read train lines and val lines\n",
    "with open(train_annotation_path) as f:\n",
    "    train_lines = f.readlines()\n",
    "with open(val_annotation_path) as f:\n",
    "    val_lines = f.readlines()\n",
    "num_train = len(train_lines)\n",
    "num_val = len(val_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3340"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSyV6g91WfL2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:1/25\n",
      "Start Training.\n",
      "step:1/3006 || Total Loss: 16055.4883 || 4.8307s/step\n",
      "step:10/3006 || Total Loss: 12513.4219 || 5.0468s/step\n",
      "step:20/3006 || Total Loss: 10202.5098 || 5.5633s/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-b65580baea9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInit_Epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFreeze_Epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n\u001b[0;32m---> 27\u001b[0;31m                                          Freeze_Epoch, Cuda, optimizer, lr_scheduler)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-f28df278f51d>\u001b[0m in \u001b[0;36mfit_one_epoch\u001b[0;34m(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, genval, Epoch, cuda, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-411d091b0831>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, targets)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# 找到哪些先验框内部包含物体\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoobj_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_loss_scale_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_loss_scale_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_anchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mnoobj_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_boxes_for_ciou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ignore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoobj_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-411d091b0831>\u001b[0m in \u001b[0;36mget_target\u001b[0;34m(self, target, anchors, in_w, in_h, ignore_threshold)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mt_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mt_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mt_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mt_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#------------------------------------#\n",
    "#   先冻结backbone训练\n",
    "#------------------------------------#\n",
    "lr = 1e-3\n",
    "Batch_size = 4\n",
    "Init_Epoch = 0\n",
    "Freeze_Epoch = 25\n",
    "        \n",
    "optimizer = optim.Adam(net.parameters(), lr, weight_decay=5e-4)\n",
    "if Cosine_lr:\n",
    "    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "else:\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "gen = Generator(Batch_size, train_lines, (input_shape[0], input_shape[1])).generate(mosaic = mosaic)\n",
    "gen_val = Generator(Batch_size, val_lines, (input_shape[0], input_shape[1])).generate(mosaic = False)\n",
    "                        \n",
    "epoch_size = int(max(1, num_train//Batch_size//2.5)) if mosaic else max(1, num_train//Batch_size)\n",
    "epoch_size_val = num_val//Batch_size\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "best_loss = 99999999.0\n",
    "best_model_weights = copy.deepcopy(net.state_dict())\n",
    "for epoch in range(Init_Epoch, Freeze_Epoch):\n",
    "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
    "                                         Freeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    with open('/output/total_loss.csv', mode='a+') as total_loss_file:\n",
    "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
    "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
    "    #    val_loss_file.write(str(val_loss.item()) + '\\n')\n",
    "torch.save(best_model_weights, '/output/yolov4_maskdetect_weights0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mn6h64xNWfL5"
   },
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "#   解冻backbone后训练\n",
    "#------------------------------------#\n",
    "lr = 1e-4\n",
    "Batch_size = 2\n",
    "Freeze_Epoch = 25\n",
    "Unfreeze_Epoch = 50\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr, weight_decay=5e-4)\n",
    "if Cosine_lr:\n",
    "    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "else:\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "gen = Generator(Batch_size, train_lines, (input_shape[0], input_shape[1])).generate(mosaic = mosaic)\n",
    "gen_val = Generator(Batch_size, val_lines, (input_shape[0], input_shape[1])).generate(mosaic = False)\n",
    "                        \n",
    "epoch_size = int(max(1, num_train//Batch_size//2.5)) if mosaic else max(1, num_train//Batch_size)\n",
    "epoch_size_val = num_val//Batch_size\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(Freeze_Epoch, Unfreeze_Epoch):\n",
    "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
    "                                         Unfreeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    with open('/content/gdrive/My Drive/cv_final/yolo_pytorch/total_loss.csv', mode='a+') as total_loss_file:\n",
    "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
    "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
    "    #    val_loss_file.write(str(val_loss.item() + '\\n')\n",
    "torch.save(best_model_weights, '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/yolov4_maskdetect_weights2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY9f2L1zWfL7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/output/1949.json','r') as file_obj:\n",
    "    b = json.load(file_obj)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13068"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 3, 5, 6, 6, 8, 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[18]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[11]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [[165, 250, 236, 277], [165, 270, 235, 289], [165, 223, 235, 249]],\n",
       " 'score': [0.923346757888794, 0.01639356091618538, 0.7466841340065002],\n",
       " 'label': [10, 1, 6]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(b)):\n",
    "    if i%3000==0:\n",
    "        print(i)\n",
    "    b[i]['label'] = [10  if j ==0 else j for j in b[i]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "14\n",
      "18\n",
      "23\n",
      "25\n",
      "26\n",
      "32\n",
      "34\n",
      "45\n",
      "58\n",
      "66\n",
      "67\n",
      "69\n",
      "70\n",
      "75\n",
      "79\n",
      "84\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(b)):\n",
    "    if i==100:\n",
    "        break\n",
    "    if 10 in b[i]['label']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    a[i]['label'].reverse()\n",
    "    a[i]['score'].reverse()\n",
    "    a[i]['bbox'].reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [[10, 37, 28, 47], [9, 28, 29, 37]],\n",
       " 'score': [0.901158332824707, 0.909404456615448],\n",
       " 'label': [10, 2]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)    \n",
    "with open('/output/0616109_6.json','w') as file_obj:\n",
    "    json.dump(b, file_obj, cls=NpEncoder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/output/0616109_6.json','r') as file_obj:\n",
    "    aaa = json.load(file_obj)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [[165, 250, 236, 277], [165, 270, 235, 289], [165, 223, 235, 249]],\n",
       " 'score': [0.923346757888794, 0.01639356091618538, 0.7466841340065002],\n",
       " 'label': [10, 1, 6]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [[10, 37, 28, 47], [9, 28, 29, 37]],\n",
       " 'score': [0.901158332824707, 0.909404456615448],\n",
       " 'label': [10, 2]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [1, 0],\n",
       " 'score': [0.6984728574752808, 0.8398340940475464],\n",
       " 'bbox': [[7, 45, 31, 56], [5, 38, 30, 46]]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[45]['bbox'].reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [1, 0],\n",
       " 'score': [0.6984728574752808, 0.8398340940475464],\n",
       " 'bbox': [[5, 38, 30, 46], [7, 45, 31, 56]]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
